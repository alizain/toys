{"id":"toys-1uw","title":"Merge fidget popper toys into single entry","description":"These all have identical play patterns and would rate the same on all 7 dimensions:\n\n- simpl-dimpl\n- dimpl-digits  \n- pop-it\n\n→ Merge all into: fidget-poppers (or pop-toys)\n\nAll are silicone bubble-popping fidget toys with the same sensory experience.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T00:58:37.943895-05:00","updated_at":"2025-12-26T01:11:59.558757-05:00","closed_at":"2025-12-26T01:11:59.558757-05:00","close_reason":"Merged: simpl-dimpl, dimpl-digits, pop-it → fidget-poppers","labels":["merge","toys"],"dependencies":[{"issue_id":"toys-1uw","depends_on_id":"toys-4l7","type":"parent-child","created_at":"2025-12-26T00:58:37.945559-05:00","created_by":"alizain"}]}
{"id":"toys-37m","title":"Fix Bradley-Terry implementation for non-exhaustive pairwise comparisons","description":"## Background\n\nThe toy rating system uses Bradley-Terry model to compute scores from pairwise comparisons across 7 dimensions. The current implementation in `scripts/compute-ratings.ts` has several issues that become critical now that we're moving to NON-EXHAUSTIVE pairwise comparisons (not all pairs will be compared).\n\n## Problem Analysis\n\nCurrent implementation issues discovered through comparison with canonical Bradley-Terry:\n\n1. **No normalization during iteration** - Scores can grow unbounded or shrink toward zero\n2. **No convergence check** - Fixed 100 iterations with no early stopping or verification\n3. **Poor edge case handling** - All-wins → ∞, all-losses → 0, no-data → arbitrary\n4. **No graph connectivity awareness** - Silent failures with disconnected comparison graphs\n\n## Target Implementation\n\nThe \"pragmatic most correct\" approach using standard MM algorithm with proper safeguards:\n\n```typescript\nfunction computeBradleyTerryScores(\n  stats: Map\u003cstring, ToyStats\u003e,\n  allToys: string[],\n  maxIterations = 100,\n  tolerance = 1e-6,\n): Map\u003cstring, number\u003e {\n  const scores = new Map\u003cstring, number\u003e()\n  \n  // Initialize uniformly\n  for (const toy of allToys) {\n    scores.set(toy, 1.0)\n  }\n\n  for (let iter = 0; iter \u003c maxIterations; iter++) {\n    const newScores = new Map\u003cstring, number\u003e()\n    let maxChange = 0\n\n    for (const toy of allToys) {\n      const toyStats = stats.get(toy)\n      \n      if (!toyStats || toyStats.opponents.size === 0) {\n        newScores.set(toy, 1.0)  // No data → neutral score\n        continue\n      }\n\n      // Effective wins (ties count as half)\n      const effectiveWins = toyStats.wins + toyStats.ties * 0.5\n      \n      // Standard MM denominator\n      let denominator = 0\n      for (const opponent of toyStats.opponents) {\n        const myScore = scores.get(toy)!\n        const oppScore = scores.get(opponent) || 1.0\n        denominator += 1 / (myScore + oppScore)\n      }\n\n      if (effectiveWins \u003e 0 \u0026\u0026 denominator \u003e 0) {\n        newScores.set(toy, effectiveWins / denominator)\n      } else {\n        // All losses: use small positive value (regularization effect)\n        newScores.set(toy, 0.01)\n      }\n    }\n\n    // NORMALIZE: sum to number of toys (keeps scores around 1.0)\n    const total = Array.from(newScores.values()).reduce((a, b) =\u003e a + b, 0)\n    const scale = allToys.length / total\n    \n    for (const toy of allToys) {\n      const normalized = newScores.get(toy)! * scale\n      maxChange = Math.max(maxChange, Math.abs(normalized - scores.get(toy)!))\n      scores.set(toy, normalized)\n    }\n\n    if (maxChange \u003c tolerance) {\n      console.log(`Converged after ${iter + 1} iterations`)\n      break\n    }\n  }\n\n  return scores\n}\n```\n\n## Key Design Decisions\n\n| Aspect | Approach | Rationale |\n|--------|----------|-----------|\n| Update formula | Standard MM: `p_i = W_i / Σ(1/(p_i + p_j))` | Proven to converge, well-understood |\n| Normalization | Sum-to-N after each iteration | Numerical stability, bounded scores |\n| Convergence | Check max change \u003c 1e-6, early stop | Efficiency + correctness verification |\n| All-losses case | Floor at 0.01 | Simple, prevents 0, normalization rescales |\n| No-data case | Score = 1.0 (neutral) | After normalization, becomes average |\n| Ties | Half-win heuristic | Good enough, matches intuition |\n\n## What We're NOT Doing (intentionally)\n\n- Full Bayesian inference - overkill\n- Newton-Raphson optimization - MM is more robust\n- Log-space computation - 1-10 scale compression handles extreme ratios\n- Davidson/Rao-Kupper tie models - adds parameters we can't estimate with sparse data\n- Formal graph connectivity checks - just document the requirement\n\n## Files to Modify\n\n- `packages/toys/scripts/compute-ratings.ts` - Main implementation\n\n## References\n\n- Wikipedia: Bradley-Terry model\n- Hunter (2004): MM algorithms for generalized Bradley-Terry models\n- Ford's Condition (1957): MLE exists iff comparison graph is strongly connected","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-26T14:30:54.060338-05:00","updated_at":"2025-12-26T14:50:07.462984-05:00","closed_at":"2025-12-26T14:50:07.462984-05:00","close_reason":"All subtasks complete: normalization, convergence, edge cases, prior pseudo-counts, documentation","labels":["algorithm","bradley-terry","toys"]}
{"id":"toys-4l7","title":"Consolidate toy entries for consistent taxonomy","description":"Review and consolidate toy entries to ensure consistent naming (brand→generic where brand doesn't affect ratings) and merge duplicate entries where play patterns and rating dimensions would be identical.\n\nGuiding principles:\n- Merge when ratings would be identical (e.g., Magna-Tiles vs PicassoTiles)\n- Keep brands that define categories (LEGO, Duplo, Hot Wheels, Schleich, Barbie)\n- Convert brand→generic when brand doesn't add distinctiveness (Crayola Crayons → Crayons)\n- Err on side of slight duplication over incorrect merging","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-26T00:57:09.956951-05:00","updated_at":"2025-12-26T01:12:39.091353-05:00","closed_at":"2025-12-26T01:12:39.091353-05:00","close_reason":"All 12 subtasks completed: 24 brand→generic renames and 5 merges executed. Net reduction of ~13 entries.","labels":["taxonomy","toys"]}
{"id":"toys-4yf","title":"Rename Green Toys branded toys to generic names","description":"These toys are common categories where the brand doesn't affect ratings:\n\n- green-toys-fire-truck → toy-fire-truck\n- green-toys-stacking-cups → stacking-cups\n- green-toys-tea-set → toy-tea-set\n\nRename folders and update any references.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T00:57:45.402391-05:00","updated_at":"2025-12-26T01:11:13.957377-05:00","closed_at":"2025-12-26T01:11:13.957377-05:00","close_reason":"Renamed: green-toys-fire-truck → toy-fire-truck, green-toys-stacking-cups → stacking-cups, green-toys-tea-set → toy-tea-set","labels":["rename","toys"],"dependencies":[{"issue_id":"toys-4yf","depends_on_id":"toys-4l7","type":"parent-child","created_at":"2025-12-26T00:57:45.403888-05:00","created_by":"alizain"}]}
{"id":"toys-63x","title":"Install Tailwind typography plugin for prose styling","description":"Install @tailwindcss/typography and import it in globals.css. The toy page already has prose classes but they're not working without the plugin.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T15:55:04.844102-05:00","updated_at":"2025-12-27T16:00:37.597291-05:00","closed_at":"2025-12-27T16:00:37.597291-05:00","close_reason":"Installed @tailwindcss/typography and added @plugin directive to globals.css"}
{"id":"toys-7rk","title":"Add confidence indicator for sparse comparison data","description":"## Problem\n\nWith non-exhaustive comparisons, some toys may have very few data points. Users should know which ratings are reliable.\n\n## Solution\n\nAdd a confidence function and optionally include in output:\n\n```typescript\nfunction getConfidence(toyStats: ToyStats | undefined): 'high' | 'medium' | 'low' {\n  if (!toyStats) return 'low'\n  const totalComparisons = toyStats.opponents.size\n  if (totalComparisons \u003e= 5) return 'high'\n  if (totalComparisons \u003e= 2) return 'medium'\n  return 'low'\n}\n```\n\n## Optional: Add to CSV output\n\nCould add a `confidence` column to ratings.csv, or create a separate confidence.csv.\n\nFor now, just add the function and log warnings for low-confidence ratings.\n\n## File\n\n`scripts/compute-ratings.ts` - add helper function and warning in main()","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-27T15:26:09.290798-05:00","updated_at":"2025-12-27T15:26:09.290798-05:00","labels":["algorithm"]}
{"id":"toys-89i","title":"Merge Paw Patrol entries into single entry","description":"Same franchise, same play patterns:\n\n- paw-patrol-figures\n- paw-patrol-vehicles\n\n→ Merge into: paw-patrol\n\nBoth are part of the same licensed toy ecosystem with similar ratings.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T00:58:43.148035-05:00","updated_at":"2025-12-26T01:12:04.741227-05:00","closed_at":"2025-12-26T01:12:04.741227-05:00","close_reason":"Merged: paw-patrol-figures, paw-patrol-vehicles → paw-patrol","labels":["merge","toys"],"dependencies":[{"issue_id":"toys-89i","depends_on_id":"toys-4l7","type":"parent-child","created_at":"2025-12-26T00:58:43.149756-05:00","created_by":"alizain"}]}
{"id":"toys-9ib","title":"Rename miscellaneous branded toys to generic names","description":"These toys are common categories where the brand doesn't affect ratings:\n\n- crayola-crayons → crayons\n- hape-pound-and-tap-bench → pound-tap-bench\n- oregon-scientific-smart-globe → interactive-globe\n- learning-resources-anatomy-model → anatomy-model\n- learning-resources-weather-station → weather-station\n- lovevery-play-gym → baby-play-gym\n- skip-hop-explore-more-roll-around-rattle → baby-rattle\n- sassy-poppin-push-toy → push-toy\n- radio-flyer-wagon → wagon\n\nRename folders and update any references.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T00:58:06.339045-05:00","updated_at":"2025-12-26T01:11:34.895346-05:00","closed_at":"2025-12-26T01:11:34.895346-05:00","close_reason":"Renamed: crayola-crayons → crayons, hape-pound-and-tap-bench → pound-tap-bench, oregon-scientific-smart-globe → interactive-globe, learning-resources-anatomy-model → anatomy-model, learning-resources-weather-station → weather-station, lovevery-play-gym → baby-play-gym, skip-hop-explore-more-roll-around-rattle → baby-rattle, sassy-poppin-push-toy → push-toy, radio-flyer-wagon → wagon","labels":["rename","toys"],"dependencies":[{"issue_id":"toys-9ib","depends_on_id":"toys-4l7","type":"parent-child","created_at":"2025-12-26T00:58:06.340596-05:00","created_by":"alizain"}]}
{"id":"toys-bxa","title":"Document \"keep separate\" taxonomy decisions","description":"These entries should remain separate despite apparent similarity, because they have meaningfully different play experiences or would rate differently on dimensions:\n\n**Brands that define categories (keep as-is):**\n- LEGO, Duplo, Hot Wheels, Schleich, Barbie, Calico Critters, Jellycat, Playmobil\n\n**Same brand, different products (keep separate):**\n- lego-classic vs lego-city-vehicles (different generativity scores)\n- All Schleich lines (horses, dinosaurs, wild animals, farm) - different themes\n- All Playmobil sets (airport, castle, pirate ship, zoo) - different themes\n- Hot Wheels vs Matchbox - different systems\n\n**Similar category, different materials/experience:**\n- gravitrax vs hape-quadrilla (magnetic/plastic vs wooden - different sensory)\n- magnetic-tiles vs magnet-foam-blocks (rigid vs soft - different ages)\n- weighted-blanket vs weighted-lap-animal (different use contexts)\n\n**Action figure franchises (keep all separate):**\n- dc-superheroes, marvel-legends, star-wars-figures, transformers, etc.\n- Each has distinct fan base and collecting patterns\n\n**Musical instruments (keep all separate):**\n- Each instrument is a distinct play experience\n\nDocument these decisions somewhere for future reference.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-26T00:59:15.081746-05:00","updated_at":"2025-12-26T01:12:20.47529-05:00","closed_at":"2025-12-26T01:12:20.47529-05:00","close_reason":"Documented in epic description - brands that define categories (LEGO, Duplo, Hot Wheels, Schleich, Barbie, Playmobil) kept separate; marble runs kept separate (different materials); action figure franchises kept separate","labels":["documentation","toys"],"dependencies":[{"issue_id":"toys-bxa","depends_on_id":"toys-4l7","type":"parent-child","created_at":"2025-12-26T00:59:15.083894-05:00","created_by":"alizain"}]}
{"id":"toys-g7f","title":"Rename National Geographic branded toys to generic names","description":"These toys are common categories where the brand doesn't affect ratings:\n\n- national-geographic-crystal-growing-kit → crystal-growing-kit\n- national-geographic-rock-collection → rock-collection\n- national-geographic-science-kit → science-kit\n\nRename folders and update any references.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T00:57:50.595827-05:00","updated_at":"2025-12-26T01:11:19.149278-05:00","closed_at":"2025-12-26T01:11:19.149278-05:00","close_reason":"Renamed: national-geographic-crystal-growing-kit → crystal-growing-kit, national-geographic-rock-collection → rock-collection, national-geographic-science-kit → science-kit","labels":["rename","toys"],"dependencies":[{"issue_id":"toys-g7f","depends_on_id":"toys-4l7","type":"parent-child","created_at":"2025-12-26T00:57:50.598-05:00","created_by":"alizain"}]}
{"id":"toys-hc8","title":"Merge Hot Wheels track builder into Hot Wheels","description":"Track builder is part of the Hot Wheels system:\n\n- hot-wheels\n- hot-wheels-track-builder\n\n→ Merge into: hot-wheels\n\nThe track system is integral to Hot Wheels play - mention tracks in the Hot Wheels content.\n\nNote: Keep matchbox-car-garage separate - different brand/system.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T00:58:48.384372-05:00","updated_at":"2025-12-26T01:12:09.928283-05:00","closed_at":"2025-12-26T01:12:09.928283-05:00","close_reason":"Merged: hot-wheels-track-builder content into hot-wheels","labels":["merge","toys"],"dependencies":[{"issue_id":"toys-hc8","depends_on_id":"toys-4l7","type":"parent-child","created_at":"2025-12-26T00:58:48.386475-05:00","created_by":"alizain"}]}
{"id":"toys-hvi","title":"Add inline documentation explaining Bradley-Terry algorithm","description":"## Problem\n\nThe algorithm is non-trivial and future maintainers need to understand what's happening.\n\n## Solution\n\nAdd JSDoc comments explaining the key concepts:\n\n```typescript\n/**\n * Compute toy ratings using the Bradley-Terry model with MM algorithm.\n * \n * The Bradley-Terry model defines: P(i beats j) = p_i / (p_i + p_j)\n * \n * We use the MM (Minorization-Maximization) algorithm to find the MLE:\n *   p_i^(new) = W_i / Σ_j(n_ij / (p_i + p_j))\n * \n * Where:\n *   - W_i = effective wins for toy i (wins + 0.5 * ties)\n *   - n_ij = number of comparisons between i and j (always 1 in our case)\n *   - The sum is over all opponents j that i has faced\n * \n * Key implementation details:\n *   - Normalize scores after each iteration for numerical stability\n *   - Early stopping when max score change \u003c tolerance\n *   - All-losses toys get small positive score (0.01) to avoid singularities\n *   - Uncompared toys get neutral score (1.0) → average after normalization\n * \n * References:\n *   - Hunter (2004): MM algorithms for generalized Bradley-Terry models\n *   - Ford (1957): MLE exists iff comparison graph is strongly connected\n * \n * @param stats - Per-toy win/loss/tie statistics from comparisons\n * @param allToys - List of all toy slugs to rate\n * @param maxIterations - Maximum iterations before stopping (default: 100)\n * @param tolerance - Convergence threshold for early stopping (default: 1e-6)\n * @returns Map of toy slug → raw Bradley-Terry score (not yet normalized to 1-10)\n */\n```\n\n## File\n\n`scripts/compute-ratings.ts` - JSDoc on `computeBradleyTerryScores()`","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T14:32:04.243701-05:00","updated_at":"2025-12-26T14:49:49.462244-05:00","closed_at":"2025-12-26T14:49:49.462244-05:00","close_reason":"Added comprehensive JSDoc explaining MM algorithm and implementation details","labels":["documentation","toys"],"dependencies":[{"issue_id":"toys-hvi","depends_on_id":"toys-37m","type":"parent-child","created_at":"2025-12-26T14:32:04.245679-05:00","created_by":"alizain"}]}
{"id":"toys-hwn","title":"Rename Melissa \u0026 Doug branded toys to generic names","description":"These toys are common categories where the brand doesn't affect ratings:\n\n- melissa-doug-alphabet-blocks → alphabet-blocks\n- melissa-doug-number-puzzles → number-puzzles  \n- melissa-doug-parking-garage → toy-parking-garage\n- melissa-doug-shape-sorter → shape-sorter\n\nRename folders and update any references.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T00:57:40.169569-05:00","updated_at":"2025-12-26T01:11:08.767481-05:00","closed_at":"2025-12-26T01:11:08.767481-05:00","close_reason":"Renamed: melissa-doug-alphabet-blocks → alphabet-blocks, melissa-doug-number-puzzles → number-puzzles, melissa-doug-parking-garage → toy-parking-garage, melissa-doug-shape-sorter → shape-sorter","labels":["rename","toys"],"dependencies":[{"issue_id":"toys-hwn","depends_on_id":"toys-4l7","type":"parent-child","created_at":"2025-12-26T00:57:40.17179-05:00","created_by":"alizain"}]}
{"id":"toys-i8h","title":"Merge magnetic tile variants into single entry","description":"These all have identical play patterns and would rate the same on all 7 dimensions:\n\n- magna-tiles\n- magna-tiles-giant (just bigger, same play)\n- picasso-tiles\n- minecraft-magnet-tiles\n\n→ Merge all into: magnetic-tiles\n\nKeep magna-tiles content as base (most well-known), mention other brands and variants in the content.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T00:58:32.75318-05:00","updated_at":"2025-12-26T01:11:54.375305-05:00","closed_at":"2025-12-26T01:11:54.375305-05:00","close_reason":"Merged: magna-tiles, magna-tiles-giant, picasso-tiles, minecraft-magnet-tiles → magnetic-tiles","labels":["merge","toys"],"dependencies":[{"issue_id":"toys-i8h","depends_on_id":"toys-4l7","type":"parent-child","created_at":"2025-12-26T00:58:32.755288-05:00","created_by":"alizain"}]}
{"id":"toys-jsq","title":"Add convergence check with early stopping","description":"## Problem\n\nCurrent implementation uses fixed 100 iterations with no convergence check. For sparse graphs, 100 may not be enough. For dense graphs, we waste computation.\n\n## Solution\n\nTrack maximum score change per iteration and stop when below tolerance:\n\n```typescript\nconst tolerance = 1e-6  // or pass as parameter\n\nfor (let iter = 0; iter \u003c maxIterations; iter++) {\n  const newScores = new Map\u003cstring, number\u003e()\n  let maxChange = 0\n\n  // ... compute newScores ...\n\n  // After normalization, track change\n  for (const toy of allToys) {\n    const normalized = newScores.get(toy)! * scale\n    maxChange = Math.max(maxChange, Math.abs(normalized - scores.get(toy)!))\n    scores.set(toy, normalized)\n  }\n\n  if (maxChange \u003c tolerance) {\n    console.log(`Converged after ${iter + 1} iterations`)\n    break\n  }\n}\n```\n\n## Parameters\n\n- `maxIterations`: default 100 (increase to 200 for safety margin)\n- `tolerance`: default 1e-6 (good balance of precision and speed)\n\n## File\n\n`scripts/compute-ratings.ts` - modify `computeBradleyTerryScores()` signature and loop","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-26T14:31:48.450981-05:00","updated_at":"2025-12-26T14:49:39.164398-05:00","closed_at":"2025-12-26T14:49:39.164398-05:00","close_reason":"Added convergence check with maxChange tracking and early stopping","labels":["algorithm","toys"],"dependencies":[{"issue_id":"toys-jsq","depends_on_id":"toys-37m","type":"parent-child","created_at":"2025-12-26T14:31:48.452671-05:00","created_by":"alizain"}]}
{"id":"toys-n4s","title":"Handle edge cases: all-losses and no-data toys","description":"## Problem\n\nCurrent implementation has poor edge case handling:\n- Toy with all losses: score → 0 (division issues)\n- Toy with no comparisons: score stays at 1.0 (arbitrary, not normalized properly)\n\n## Solution\n\n### No-data case (toy never compared on this dimension)\n\n```typescript\nif (!toyStats || toyStats.opponents.size === 0) {\n  newScores.set(toy, 1.0)  // Neutral score, will be normalized to average\n  continue\n}\n```\n\n### All-losses case (effectiveWins = 0)\n\n```typescript\nif (effectiveWins \u003e 0 \u0026\u0026 denominator \u003e 0) {\n  newScores.set(toy, effectiveWins / denominator)\n} else {\n  // All losses: use small positive value (acts as soft regularization)\n  newScores.set(toy, 0.01)\n}\n```\n\n## Rationale\n\n- `0.01` is arbitrary but normalization will rescale appropriately\n- The toy will end up with a low score relative to others (correct behavior)\n- Prevents division by zero and log(0) issues downstream\n\n## File\n\n`scripts/compute-ratings.ts` - inside the per-toy loop in `computeBradleyTerryScores()`","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-26T14:31:53.746987-05:00","updated_at":"2025-12-26T14:49:44.312308-05:00","closed_at":"2025-12-26T14:49:44.312308-05:00","close_reason":"Edge cases handled via prior pseudo-counts (0.5 wins, 0.5 losses)","labels":["algorithm","toys"],"dependencies":[{"issue_id":"toys-n4s","depends_on_id":"toys-37m","type":"parent-child","created_at":"2025-12-26T14:31:53.748893-05:00","created_by":"alizain"}]}
{"id":"toys-obb","title":"Merge gears building toys into single entry","description":"Same type of toy, same ratings:\n\n- gears-gears-gears\n- learning-resources-gears-robotics\n\n→ Merge into: building-gears (or gear-building-toys)\n\nBoth are interlocking gear construction toys with similar play patterns.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T00:58:53.747967-05:00","updated_at":"2025-12-26T01:12:15.277865-05:00","closed_at":"2025-12-26T01:12:15.277865-05:00","close_reason":"Merged: gears-gears-gears, learning-resources-gears-robotics → building-gears","labels":["merge","toys"],"dependencies":[{"issue_id":"toys-obb","depends_on_id":"toys-4l7","type":"parent-child","created_at":"2025-12-26T00:58:53.749475-05:00","created_by":"alizain"}]}
{"id":"toys-q2r","title":"Rename Educational Insights branded toys to generic names","description":"These toys are common categories where the brand doesn't affect ratings:\n\n- educational-insights-geosafari-microscope → kids-microscope\n- educational-insights-telescope → kids-telescope\n\nRename folders and update any references.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T00:57:55.861998-05:00","updated_at":"2025-12-26T01:11:24.356775-05:00","closed_at":"2025-12-26T01:11:24.356775-05:00","close_reason":"Renamed: educational-insights-geosafari-microscope → kids-microscope, educational-insights-telescope → kids-telescope","labels":["rename","toys"],"dependencies":[{"issue_id":"toys-q2r","depends_on_id":"toys-4l7","type":"parent-child","created_at":"2025-12-26T00:57:55.864458-05:00","created_by":"alizain"}]}
{"id":"toys-std","title":"Create /dimensions page explaining the 7 rating dimensions","description":"Add a page at /dimensions that explains the rating framework. Hero intro + 7 sections with philosophical quotes, scoring rubrics, and key questions. Use subagents to research authentic quotes from Montessori, Papert, Malaguzzi, and Piaget.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-27T15:55:04.793349-05:00","updated_at":"2025-12-27T16:04:51.398548-05:00","closed_at":"2025-12-27T16:04:51.398548-05:00","close_reason":"Created /dimensions page with hero, 7 dimension sections with philosophical quotes, scoring rubrics, and key questions. Added navigation link from homepage."}
{"id":"toys-vma","title":"Fix biome-ignore-all placement in toys globals.css","description":"Biome reports that top-level suppressions must be at the beginning of the file. The biome-ignore-all comment at line 74 in app/globals.css should be moved to the top or renamed to biome-ignore.","status":"open","priority":3,"issue_type":"chore","created_at":"2025-12-25T18:44:43.2366-05:00","updated_at":"2025-12-25T18:44:43.2366-05:00","labels":["linting","toys"]}
{"id":"toys-vxt","title":"Rename VTech/Fisher-Price branded toys to generic names","description":"These toys are common categories where the brand doesn't affect ratings:\n\n- fisher-price-rock-a-stack → stacking-rings\n- vtech-sit-to-stand-walker → baby-walker\n- vtech-touch-and-learn-activity-desk → activity-desk\n\nRename folders and update any references.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T00:58:01.122768-05:00","updated_at":"2025-12-26T01:11:29.694886-05:00","closed_at":"2025-12-26T01:11:29.694886-05:00","close_reason":"Renamed: fisher-price-rock-a-stack → stacking-rings, vtech-sit-to-stand-walker → baby-walker, vtech-touch-and-learn-activity-desk → activity-desk","labels":["rename","toys"],"dependencies":[{"issue_id":"toys-vxt","depends_on_id":"toys-4l7","type":"parent-child","created_at":"2025-12-26T00:58:01.124958-05:00","created_by":"alizain"}]}
{"id":"toys-wmx","title":"Add prior pseudo-counts to fix non-convergence with undefeated toys","description":"## Problem\n\nThe Bradley-Terry algorithm **never converges** with real data because undefeated toys (W\u003e0, L=0) cause their MLE scores to tend toward infinity. This was observed in all 7 dimensions:\n\n```\ngenerativity:            Did NOT converge (finger-paint: W=8 L=0 → 41.2)\ndevelopmental_longevity: Did NOT converge (crayons: W=5 L=0 → 13.9)\nproductive_challenge:    Did NOT converge (cuisenaire-rods: W=3 L=0 → 71.1)\nsensory_engagement:      Did NOT converge (climbing-dome: W=2 L=0 → 61.0)\nexpressive_range:        Did NOT converge (jellycat: W=2 L=0 → 11.9)\nsocial_affordance:       Did NOT converge (jellycat: W=1 L=0 → 5.6)\npractical_sustainability: Did NOT converge (checkers: W=3 L=0 → 33.2)\n```\n\nThe denominator for defeated toys keeps growing as undefeated opponents' scores explode:\n```\nactivity-desk in social_affordance:\n  Iter 50:  denom=1,374\n  Iter 100: denom=6,765\n  Iter 200: denom=49,852  ← still growing!\n```\n\n## Root Cause\n\nFord's Condition (1957): Bradley-Terry MLE exists **only if** no item has won all its comparisons. With undefeated items, the MLE is literally infinity - the algorithm will never converge.\n\n## Solution\n\nAdd Bayesian prior pseudo-counts that act as \"virtual games\" against a reference opponent:\n\n```typescript\nconst PRIOR_WINS = 0.5\nconst PRIOR_LOSSES = 0.5\n\nconst effectiveWins = toyStats.wins + toyStats.ties * 0.5 + PRIOR_WINS\nconst effectiveGames = toyStats.opponents.size + PRIOR_WINS + PRIOR_LOSSES\n```\n\nThen use `effectiveGames` in the denominator calculation. This is equivalent to assuming each toy has played one virtual game with a 50/50 outcome before seeing any real data.\n\n## Why This Works\n\n- Undefeated toy (W=8, L=0): effectiveWins = 8.5, has a \"virtual loss\" preventing infinity\n- All-losses toy (W=0, L=5): effectiveWins = 0.5, has a \"virtual win\" preventing zero\n- Well-compared toy (W=10, L=8): effectiveWins = 10.5, prior has minimal effect\n\nThe prior shrinks toward 50% for toys with few comparisons (appropriate uncertainty) and has negligible effect on toys with many comparisons.\n\n## File\n\n`scripts/compute-ratings.ts` - modify `computeBradleyTerryScores()`\n\n## Acceptance Criteria\n\n- [ ] All 7 dimensions converge within 200 iterations\n- [ ] No raw scores explode to unreasonable values (\u003e100)\n- [ ] Undefeated toys still rank high, just not infinitely high","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-26T14:45:36.218863-05:00","updated_at":"2025-12-26T14:49:54.617562-05:00","closed_at":"2025-12-26T14:49:54.617562-05:00","close_reason":"Added prior pseudo-counts (0.5 wins, 0.5 losses) - all 7 dimensions now converge","labels":["algorithm","bradley-terry","critical","toys"],"dependencies":[{"issue_id":"toys-wmx","depends_on_id":"toys-37m","type":"parent-child","created_at":"2025-12-26T14:45:36.221393-05:00","created_by":"alizain"}]}
{"id":"toys-yfz","title":"Add normalization after each Bradley-Terry iteration","description":"## Problem\n\nCurrent implementation never normalizes scores during iteration. Scores can grow unbounded or shrink toward zero, causing numerical instability.\n\n## Solution\n\nAfter computing `newScores` for all toys in each iteration, normalize so scores sum to `allToys.length`:\n\n```typescript\n// NORMALIZE: sum to number of toys (keeps scores around 1.0)\nconst total = Array.from(newScores.values()).reduce((a, b) =\u003e a + b, 0)\nconst scale = allToys.length / total\n\nfor (const toy of allToys) {\n  const normalized = newScores.get(toy)! * scale\n  scores.set(toy, normalized)\n}\n```\n\n## Why sum-to-N instead of sum-to-1?\n\nKeeps scores around 1.0 which is numerically convenient. Either works mathematically.\n\n## File\n\n`scripts/compute-ratings.ts` - inside the iteration loop in `computeBradleyTerryScores()`","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-26T14:31:43.240995-05:00","updated_at":"2025-12-26T14:49:34.014386-05:00","closed_at":"2025-12-26T14:49:34.014386-05:00","close_reason":"Implemented normalization after each iteration (sum to N)","labels":["algorithm","toys"],"dependencies":[{"issue_id":"toys-yfz","depends_on_id":"toys-37m","type":"parent-child","created_at":"2025-12-26T14:31:43.242932-05:00","created_by":"alizain"}]}
{"id":"toys-zo3","title":"Add confidence indicator for sparse comparison data","description":"## Problem\n\nWith non-exhaustive comparisons, some toys may have very few data points. Users should know which ratings are reliable.\n\n## Solution\n\nAdd a confidence function and optionally include in output:\n\n```typescript\nfunction getConfidence(toyStats: ToyStats | undefined): 'high' | 'medium' | 'low' {\n  if (!toyStats) return 'low'\n  const totalComparisons = toyStats.opponents.size\n  if (totalComparisons \u003e= 5) return 'high'\n  if (totalComparisons \u003e= 2) return 'medium'\n  return 'low'\n}\n```\n\n## Optional: Add to CSV output\n\nCould add a `confidence` column to ratings.csv, or create a separate confidence.csv.\n\nFor now, just add the function and log warnings for low-confidence ratings:\n\n```typescript\n// In main(), after computing scores:\nfor (const toy of allToys) {\n  const dimStats = stats.get(dim)?.get(toy)\n  if (getConfidence(dimStats) === 'low') {\n    console.warn(`Warning: ${toy} has low confidence on ${dim} (few comparisons)`)\n  }\n}\n```\n\n## File\n\n`scripts/compute-ratings.ts` - add helper function and warning in main()","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T14:31:59.024115-05:00","updated_at":"2025-12-27T15:26:36.547044-05:00","closed_at":"2025-12-27T15:26:36.547044-05:00","close_reason":"Migrated to ~/Experiments/toys repo as toys-7rk","labels":["algorithm","toys"],"dependencies":[{"issue_id":"toys-zo3","depends_on_id":"toys-37m","type":"parent-child","created_at":"2025-12-26T14:31:59.02566-05:00","created_by":"alizain"}]}
